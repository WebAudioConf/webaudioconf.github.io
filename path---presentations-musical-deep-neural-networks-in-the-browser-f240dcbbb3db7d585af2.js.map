{"version":3,"sources":["webpack:///path---presentations-musical-deep-neural-networks-in-the-browser-f240dcbbb3db7d585af2.js","webpack:///./.cache/json/presentations-musical-deep-neural-networks-in-the-browser.json"],"names":["webpackJsonp","478","module","exports","pathContext","abstract","authors","link","name","slug","title","type"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,aAAeC,SAAA,69BAAAC,UAAo/BC,KAAA,uBAAAC,KAAA,oBAAuDC,KAAA,8CAAAC,MAAA,8CAAAC,KAAA","file":"path---presentations-musical-deep-neural-networks-in-the-browser-f240dcbbb3db7d585af2.js","sourcesContent":["webpackJsonp([179933011456810],{\n\n/***/ 478:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"pathContext\":{\"abstract\":\"2018 is the year deep neural networks have arrived in the web browser. This development has many exciting prospects. One of them is that all the work AI researchers have put into musical applications of neural nets is suddenly available to use in web apps. We can now use generative musical deep learning models and build interactive web-based experiences on top of them, with the help of Web Audio and the rest of the web platform.\\n\\nIn this talk I will present some recent experiments I’ve made using deep neural nets and Web Audio in the browser. They’re mostly based on Google’s Magenta.js library and neural net models trained by the Magenta team. We’ll see how recurrent neural networks can be used to build melodic “autocompletion” tools and arpeggiators, as well as generative drum patterns. We’ll also see how to use variational autoencoder models to explore latent musical spaces: Interpolating between melodies, and exploring musical generative space with vector arithmetic.\",\"authors\":[{\"link\":\"https://teropa.info/\",\"name\":\"Tero Parviainen\"}],\"slug\":\"musical-deep-neural-networks-in-the-browser\",\"title\":\"Musical Deep Neural Networks in the Browser\",\"type\":\"talk\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---presentations-musical-deep-neural-networks-in-the-browser-f240dcbbb3db7d585af2.js","module.exports = {\"pathContext\":{\"abstract\":\"2018 is the year deep neural networks have arrived in the web browser. This development has many exciting prospects. One of them is that all the work AI researchers have put into musical applications of neural nets is suddenly available to use in web apps. We can now use generative musical deep learning models and build interactive web-based experiences on top of them, with the help of Web Audio and the rest of the web platform.\\n\\nIn this talk I will present some recent experiments I’ve made using deep neural nets and Web Audio in the browser. They’re mostly based on Google’s Magenta.js library and neural net models trained by the Magenta team. We’ll see how recurrent neural networks can be used to build melodic “autocompletion” tools and arpeggiators, as well as generative drum patterns. We’ll also see how to use variational autoencoder models to explore latent musical spaces: Interpolating between melodies, and exploring musical generative space with vector arithmetic.\",\"authors\":[{\"link\":\"https://teropa.info/\",\"name\":\"Tero Parviainen\"}],\"slug\":\"musical-deep-neural-networks-in-the-browser\",\"title\":\"Musical Deep Neural Networks in the Browser\",\"type\":\"talk\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/presentations-musical-deep-neural-networks-in-the-browser.json\n// module id = 478\n// module chunks = 179933011456810"],"sourceRoot":""}