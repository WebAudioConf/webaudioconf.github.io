{"version":3,"sources":["webpack:///path---presentations-metaprogramming-strategies-for-audioworklets-7ea44a182de480185f4e.js","webpack:///./.cache/json/presentations-metaprogramming-strategies-for-audioworklets.json"],"names":["webpackJsonp","477","module","exports","pathContext","abstract","authors","link","name","slug","title","type"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,aAAeC,SAAA,i3BAAAC,UAAw4BC,KAAA,kCAAAC,KAAA,oBAAkEC,KAAA,+CAAAC,MAAA,+CAAAC,KAAA","file":"path---presentations-metaprogramming-strategies-for-audioworklets-7ea44a182de480185f4e.js","sourcesContent":["webpackJsonp([233696062175660],{\n\n/***/ 477:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"pathContext\":{\"abstract\":\"The introduction of AudioWorklets to the Web Audio API greatly expands the capabilities of audio in the browser. However, managing state between the various threads AudioWorklets occupy entails a fair amount of complexity, particularly when designing dynamic music programming environments where exact digital signal processing requirements cannot be known ahead of time. Such environments are commonly used for live coding performance, interactive composition, and coding playgrounds for musical experimentation.\\n\\nOur research explores metaprogramming strategies to create AudioWorklet implementations for two JavaScript libraries, Genish.js and Gibberish.js. These strategies help hide the complexities of inter-thread communication from end-users of the libraries and enable of variety of music and audio programming techniques that would otherwise be difficult to achieve.\",\"authors\":[{\"link\":\"http://www.charlie-roberts.com/\",\"name\":\"Charles Roberts\"}],\"slug\":\"metaprogramming-strategies-for-audioworklets\",\"title\":\"Metaprogramming Strategies for AudioWorklets\",\"type\":\"paper\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---presentations-metaprogramming-strategies-for-audioworklets-7ea44a182de480185f4e.js","module.exports = {\"pathContext\":{\"abstract\":\"The introduction of AudioWorklets to the Web Audio API greatly expands the capabilities of audio in the browser. However, managing state between the various threads AudioWorklets occupy entails a fair amount of complexity, particularly when designing dynamic music programming environments where exact digital signal processing requirements cannot be known ahead of time. Such environments are commonly used for live coding performance, interactive composition, and coding playgrounds for musical experimentation.\\n\\nOur research explores metaprogramming strategies to create AudioWorklet implementations for two JavaScript libraries, Genish.js and Gibberish.js. These strategies help hide the complexities of inter-thread communication from end-users of the libraries and enable of variety of music and audio programming techniques that would otherwise be difficult to achieve.\",\"authors\":[{\"link\":\"http://www.charlie-roberts.com/\",\"name\":\"Charles Roberts\"}],\"slug\":\"metaprogramming-strategies-for-audioworklets\",\"title\":\"Metaprogramming Strategies for AudioWorklets\",\"type\":\"paper\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/presentations-metaprogramming-strategies-for-audioworklets.json\n// module id = 477\n// module chunks = 233696062175660"],"sourceRoot":""}